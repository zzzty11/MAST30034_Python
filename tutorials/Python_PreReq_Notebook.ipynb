{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946dddeb",
   "metadata": {},
   "source": [
    "# Pre-Requisite Notebook\n",
    "## Welcome\n",
    "Welcome to Applied Data Science for 2023 Semester 2! \n",
    "- We will be using Python, PySpark and Git for the majority of this subject. These tools are staples for big data processing in the workplace.\n",
    "- This notebook will get you up to speed setting up the environment you will need for this course.\n",
    "- *You must complete this notebook before the first workshop of the course.*\n",
    "- Note that **tutorial attendance will be marked after the first 3 tutorials for the industry project component.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511833d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0979d",
   "metadata": {},
   "source": [
    "## `git` (GitHub) Summary\n",
    "_Whilst this should have been covered in prerequisite subjects, a refresher may be in order_. For this subject, the minimal requirement for `git` is:\n",
    "1. `clone`: copy an existing repo from remote (repository) into your local destination.\n",
    "2. Publishing new changes:\n",
    "  - `add` + `commit`: create a new snapshot of the local repository and commit the changes.\n",
    "  - `push`: upload your local commits to remote.\n",
    "3. Syncing unseen changes:\n",
    "  - `fetch`: download unseen commits from remote to local.\n",
    "  - `merge`: merge the commits from remote with changes in local.\n",
    "    - If local has no new changes (or `is up to date`), the merge does not create new snapshot.\n",
    "    - Otherwise, changes will be automatically merged if there is no *conflict*, else you need to resolve the conflict. You will need to `commit` the merge result once this process finishes.\n",
    "      - Question: After `merge`, is the local and remote now synced? Why or why not?\n",
    "  - `pull`: Shorthand for chaining `fetch` and `merge`\n",
    "  \n",
    "Graphical illustration:\n",
    "![gitoverview](../media/git-process.png)\n",
    "\n",
    "4. Authentication:\n",
    "  - For GitHub, [Personal Access Tokens (PAT)](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token) is required as a security measure.\n",
    "\n",
    "### GitHub Desktop\n",
    "GitHub Desktop hides lots of the process under-the-hood. It is good for those who are not familiar with `git` and honestly, we use it for industry work because its easy.\n",
    "\n",
    "**Cloning:** \n",
    "1. Download [GitHub Desktop](https://desktop.github.com/)\n",
    "2. Login with your credentials\n",
    "3. On the top-left menu, click on `Add` -> `Clone repository...`\n",
    "4. Enter https://github.com/liamhodg/MAST30034_Python as the URL\n",
    "5. Click on `Clone`.\n",
    "6. Done!\n",
    "\n",
    "**Publishing:**\n",
    "1. Add changes.\n",
    "2. Click on the `MAST30034_Python` repo.\n",
    "3. Add a summary (i.e `\"removed incorrect transformation for xyz\"`)\n",
    "4. Commit to `main` (or your specified `branch` if you know what it is)\n",
    "5. Push, and you are done.\n",
    "\n",
    "**Syncing:**\n",
    "1. Click on the `MAST30034_Python` repo.\n",
    "2. Click `Fetch origin` (refresh icon)\n",
    "3. Pull, and you are done.\n",
    "\n",
    "### `git` CLI (Command Line Interface)\n",
    "If you are using `git` CLI, you will need PAT:\n",
    "1. Visit https://github.com/settings/tokens \n",
    "2. Generate a token (set it to expire end of this semester).\n",
    "3. Add changes and commit as usual.\n",
    "4. Now, after adding your `username`, you will be prompted with `password`. Rather than using your GitHub password, you should use your generated PAT here.\n",
    "5. Done!\n",
    "\n",
    "**Cloning:** \n",
    "1. Open a terminal (yes it is commandline `git` for this to work).\n",
    "2. `git clone HTTPS` (where HTTPS is the https url to your gitlab repo).\n",
    "3. Enter your credentials (with PAT).\n",
    "4. Done.\n",
    "\n",
    "**Publishing:** \n",
    "1. Change directories to inside your repository (`cd NAME_OF_REPO_FOLDER`).\n",
    "2. `git add -A` (this will stage all changed/untracked files files for the next commit, ignored files are excepted). You can use `git status` to track changed files before adding.\n",
    "3. `git commit -m \"message\"` (make a commit with a message).\n",
    "5. `git push`\n",
    "6. Enter your credentials.\n",
    "    - Here, use the same username\n",
    "    - BUT, instead of your password, use the PAT you generated.\n",
    "7. Done.\n",
    "\n",
    "**Syncing:** \n",
    "1. Change directories to inside your repository (`cd NAME_OF_REPO_FOLDER`).\n",
    "2. `git pull`\n",
    "3. Done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d59464",
   "metadata": {},
   "source": [
    "have already download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146256b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed593b88",
   "metadata": {},
   "source": [
    "## General Tips for Jupyter Notebook\n",
    "Cell shortcuts:\n",
    "- `shift + enter` : Run current cell (equivalent of pressing <button class='btn btn-default btn-xs'><i class=\"fa-play fa\"></i><span class=\"toolbar-btn-label\">Run</span></button>)\n",
    "- `ctrl + enter` : Run selected cells\n",
    "\n",
    "Command mode (press `esc` to enter):\n",
    "- `m` : Makes the cell markdown\n",
    "- `y` : Makes the cell into code\n",
    "- `a` : Insert cell above\n",
    "- `b` : Insert cell above\n",
    "- double `d` : Delete current cell\n",
    "\n",
    "Code Shortcuts:\n",
    "- `shift + tab` : brings function arguments\n",
    "\n",
    "Multiline Cursor:\n",
    "- Hold down `ctrl` on Windows or `cmd` on Mac and click on the places you wish to edit all together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecaeef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d129a",
   "metadata": {},
   "source": [
    "## Python / Requests\n",
    "This notebook will explain how to use requests to download files via Python.\n",
    "\n",
    "1. There are several libraries and packages available for Python when it comes to requesting data. For this tutorial, we'll use `urllib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52550d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T20:52:15.041722Z",
     "start_time": "2023-07-11T20:52:15.039550Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13523f0",
   "metadata": {},
   "source": [
    "2. We now want to set an output directory. You can manually create it OR you can also use Python to do so. We will be using the latter method for automation purposes. To do so, we will use the [`os` library](https://docs.python.org/3/library/os.html#os.mkdir).\n",
    "\n",
    "Important (Paths): \n",
    "- Windows Users: https://www.computerhope.com/issues/ch001708.htm#windows\n",
    "- MacOS/Linux/WSL Users: https://www.computerhope.com/issues/ch001708.htm#linux\n",
    "- `..` is used to _go up_ a level (i.e. the back button).\n",
    "\n",
    "We will make a new folder _outside_ this `tutorials/tute_1` folder inside the root `MAST30034` directory. To do so, we will use `../data` to \"exit\" the current directory or \"go up\" to the parent directory. Then, we will go into the `data` folder to create subdirectories.\n",
    "\n",
    "If you cloned the repo, you should already have the `data/taxi_zones` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd9bd35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T20:52:15.045618Z",
     "start_time": "2023-07-11T20:52:15.043068Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# from the current `tute_1` directory, go back two levels to the `MAST30034` directory\n",
    "output_relative_dir = '../data/'\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    \n",
    "# now, for each type of data set we will need, we will create the paths\n",
    "for target_dir in ('tlc_data', 'tute_data'): # taxi_zones should already exist\n",
    "    if not os.path.exists(output_relative_dir + target_dir):\n",
    "        os.makedirs(output_relative_dir + target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc4dd5",
   "metadata": {},
   "source": [
    "3. Now, we will download the required datasets. For this tutorial, we will only use January-February, but you can adjust it to your requirements.\n",
    "\n",
    "**Please only use the years where there are zones (post 2015).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb62526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T20:52:15.048828Z",
     "start_time": "2023-07-11T20:52:15.047238Z"
    }
   },
   "outputs": [],
   "source": [
    "YEAR = '2024'\n",
    "# adjust the range function to the numerical months i.e 1 = jan, 2 = feb, etc...\n",
    "# MONTHS = range(1, 13)\n",
    "MONTHS = range(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14395028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T20:52:15.052305Z",
     "start_time": "2023-07-11T20:52:15.050760Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is the URL template as of 07/2023\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\"#year-month.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613317b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T21:23:35.202286Z",
     "start_time": "2023-07-11T21:23:15.944342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n"
     ]
    }
   ],
   "source": [
    "# data output directory is `data/tlc_data/`\n",
    "tlc_output_dir = output_relative_dir + 'tlc_data'\n",
    "\n",
    "for month in MONTHS:\n",
    "    # 0-fill i.e 1 -> 01, 2 -> 02, etc\n",
    "    month = str(month).zfill(2) \n",
    "    print(f\"Begin month {month}\")\n",
    "    \n",
    "    # generate url\n",
    "    url = f'{URL_TEMPLATE}{YEAR}-{month}.parquet'\n",
    "    # generate output location and filename\n",
    "    output_dir = f\"{tlc_output_dir}/{YEAR}-{month}.parquet\"\n",
    "    # download\n",
    "    urlretrieve(url, output_dir) \n",
    "    \n",
    "    print(f\"Completed month {month}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accb3c8",
   "metadata": {},
   "source": [
    "4. The shapefile is inside the zip file from https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page :\n",
    "    - https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\n",
    "    - https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip\n",
    "    \n",
    "and now we are done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441620d4",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d339434",
   "metadata": {},
   "source": [
    "# Working with Larger Datasets with a Scalable Solution!\n",
    "Consider the size of the datasets you have worked with at Uni. Probably a few hundred megabytes or a couple gigabytes. Whilst `pandas` and `Excel` do have their use cases, it is not feasible to use them when you work with larger datasets over several gigabytes. You have been working with moderately sized data. In this subject, you will be working with larger datasets (not quite big data).\n",
    "\n",
    "For example:\n",
    "1. 20k rows would be hard for Excel, but easy for `pandas`.\n",
    "2. A few million records would be doable for `pandas` depending on RAM (let's say 16GB or 32GB to be generous).\n",
    "3. Now, consider 100 million rows over several gigabytes. `pandas` **is not your solution**.\n",
    "\n",
    "Why?\n",
    "\n",
    "`pandas` works in-memory. That is, you are limited by RAM which can be hard to come across for the average person. Even with 32GB or 64GB memory, it is best to use Apache Spark, which is designed to work with large datasets.\n",
    "\n",
    "![image.png](https://spark.apache.org/images/spark-logo-trademark.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08199e46",
   "metadata": {},
   "source": [
    "**Disclaimer:**\n",
    "- Windows 10 or 11 users are required to install `WSL` or `WSL2` for `pyspark`. This is something that you should take the time to learn how to use and install now for a future career in the tech industry. If you have yet to install it, please visit https://learn.microsoft.com/en-us/windows/wsl/install\n",
    "- MacOS (Intel) or Linux is all good. If you are using an M1, M2, or M3 chip, you will need to follow some specific instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3865f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('../data/tlc_data/2024-01.parquet')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb83bf4",
   "metadata": {},
   "source": [
    "You can then follow the tutorial using the alternative `pandas` syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4454221",
   "metadata": {},
   "source": [
    "#### Before we begin...\n",
    "*It may be a good idea to have a chatbot window open for this process: either [ChatGPT](https://chatgpt.com/), [Meta AI](https://www.meta.ai/), or [Gemini](https://gemini.google.com/app). If you encounter any errors, copy and paste the last few lines of the error into the chatbot to ask for assistance. Do not blindly follow its advice - read the response carefully to see if it can solve your problem. This deals with 90% of errors one might encounter. If you encounter other errors with these steps, please visit Liam Hodgkinson during consultation hours.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46544744",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "\n",
    "0. (Pre-Req) Install WSL2 for Windows 10 users. MacOS users, please ensure your terminal is set to `bash`.\n",
    "1. We **strongly recommend** a fresh environment for this subject as there can be package conflicts. If you are getting errors, please reinstall the environment *from scratch* before asking for help.\n",
    "2. If you are using WSL, it is recommended you install Visual Studio Code and follow [these instructions](https://code.visualstudio.com/docs/remote/wsl-tutorial).\n",
    "3. Install `Java` and `PySpark`.\n",
    "\n",
    "**All devices other than MacOS (Linux / WSL):**\n",
    "\n",
    "```bash\n",
    "# Update apt formula\n",
    "sudo apt update\n",
    "# install java\n",
    "sudo apt install openjdk-8-jdk -y\n",
    "# add to path\n",
    "echo 'JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"' | sudo tee -a /etc/environment\n",
    "# apply to environment\n",
    "source /etc/environment\n",
    "# install spark\n",
    "pip3 install pyspark pyarrow pandas\n",
    "```\n",
    "    \n",
    "**MacOS:**\n",
    "1. Install [Homebrew](https://brew.sh/). If your shell prompts to set `zsh` as default shell with `chsh -s /bin/zsh`, run that first!!  \n",
    "2. Install and setup `Java` and `JAVA_HOME` (spark uses `Java` for backend, similar to how `Python` sits on top of `C`).\n",
    "```bash\n",
    "# For Intel CPU\n",
    "# install java 8 and link to system java wrapper\n",
    "brew install openjdk@8 \n",
    "# For newer version of brew, try the command below if brew install doesn't work\n",
    "#brew install --cask homebrew/cask-versions/adoptopenjdk8\n",
    "sudo ln -sfn /usr/local/opt/openjdk@8/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-8.jdk\n",
    "# add to path (earlier OSX defaults to bash while newer ones defaults to zsh)\n",
    "echo 'export JAVA_HOME=\"$(/usr/libexec/java_home -v1.8)\"' | tee -a $HOME/.bashrc $HOME/.zshrc\n",
    "```\n",
    "\n",
    "If you are using MacOS (M1 or M2 chip), follow [this guide](https://code2care.org/q/install-native-java-jdk-jre-on-apple-silicon-m1-mac) for Java JDK or [this guide](https://gist.github.com/brianspiering/1e690b593db025b5acee920fa7330366)\n",
    "\n",
    "3. Install python packages/spark\n",
    "```bash\n",
    "# reload java path\n",
    "source $HOME/.bashrc ; source $HOME/.zshrc\n",
    "# install spark. Note: if you are using anaconda/conda environments, you need to make sure the pip3 is the correct pip3!\n",
    "# Or you should install with conda directly!\n",
    "#conda install pyspark pyarrow pandas\n",
    "pip3 install pyspark pyarrow pandas==1.5.3\n",
    "```\n",
    "\n",
    "Run the code below to see if you have installed it. As long as it runs (despite red warnings) and there are no errors, you're ready to go!\n",
    "\n",
    "Troubleshooting guides:\n",
    "1. The module is still not found after I installed everything!\n",
    "    - run `which pip` `which python` in your terminal and compare that with results of `import sys; sys.executable` running from your jupyter notebook. They have to be the same path (why?).\n",
    "    - If not same path, change the kernel of your jupyter notebook to using that python kernel.\n",
    "    \n",
    "2. The java instance stopped when executing the cell\n",
    "    - Ensure java is installed (commands executes without error)\n",
    "    - make sure `echo $JAVA_HOME` produces the proper location (i.e. it points at where your java is installed)\n",
    "    \n",
    "3. `conda`, `pip`, `apt`, `brew`... not found!\n",
    "    - Install the required softwares and make sure their home folder are present in your `echo $PATH`\n",
    "    \n",
    "4. I am using Windows and I don't want to use WSL\n",
    "    - NO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b4fd9",
   "metadata": {},
   "source": [
    "#### Now run the following code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import traceback\n",
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "BOLD = '\\033[1m'\n",
    "RESET = '\\033[0m'\n",
    "\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "    # Create a spark session (which will run spark jobs)\n",
    "    spark = (\n",
    "        SparkSession.builder.appName(\"MAST30034 Tutorial\")\n",
    "        .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "        .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "        .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    print(f\"{GREEN}{BOLD}Success! Your environment is set up and you are ready for the first workshop.{RESET}\")\n",
    "except Exception as e:\n",
    "    print(f\"{RED}{BOLD}Something went wrong. Reinstall and try again.{RESET}\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
